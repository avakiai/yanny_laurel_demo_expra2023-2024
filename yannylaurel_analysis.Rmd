---
title: "Yanny-Laurel Analysis"
output:
  html_document:
    df_print: paged
---

# Demo Experiment Analysis

## Getting Started: R Markdown

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
plot(cars)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

---

### Setup
Hello!

Let's get started. You should have downloaded the Yanny/Laurel demo repository from Github, but if not you can do so now. 

First, set working directory to where this file is by going to the ```Session``` tab, then ```Set Workspace Directory > To Source File Location```.

Something like this should show up in your console: ```setwd("[wherever you saved the repository]/yanny-laurel-demo")```


### Set paths

```{r}
# remember to set working directory to source file location
data_path = file.path('./data') 
results_path = file.path('./results')

```
 

### Load Packages & Functions
```{r warning=FALSE}
# install.packages("tidyverse") # if you don't have tidyverse installed, install it now
library(tidyverse)
```

**Note**: You should have a version of R that is at least as recent as R 4.1.0
You should also have the latest version of tidyverse, 1.3.1. 

To check your R installation, type ```R.version``` in the console. 
To check which version of a certain package you have, you can type ```packageVersion("tidyverse")``` 
into the console. Replace the part in the "" to adapt it to any other packages you want to check. 


### Load Data
```{r}
data_file <- file.path(data_path,"data.csv")
data <- read.csv(data_file, row.names = NULL) %>% 
                      dplyr::mutate(participant = as.factor(participant), # code as categorical variables
                                    sex = as.factor(sex))
```


### Exploring the data
Use `summary` to get an overview of the data and variables...
```{r}
summary(???)
```

First let's look at the participant variables. What is the demographic breakdown of our dataset? 
```{r}
hist(???) 

```
Here, it's counting up all the observations. How can we get it to count only the unique occurences?
 
```{r}
age_dat <- data %>% dplyr::group_by(participant) %>% summarise(age = unique(age))
 
hist(age_dat$age)
```

Okay, let's move on to our IV & DV's. 
We're going to focus on the proportion of trials in which participants responded 'Yanny'.

```{r}
hist(???)
```
What we actually want to know is how people's responses varied based on the level of acoustic manipulation, indexed by `stim_idx`. We also want a summary based on each participant. 


### 1. Calculate Proportion Yanny
Here we will start using tidyverse functions heavily. A lot of functions for data wrangling
come from the ```dplyr``` package. It may be helpful to check out the [dplyr documentation](https://dplyr.tidyverse.org/)
get a sense of how these functions operate. (Also, Google is your friend. :))

**Note**: You can always check the documentation of a function by typing ```? [funcion name]``` in the console. 

We'll use `dplyr::summarise` to get some summary statistics from our data in data.frame format:
```{r message=FALSE, warning=FALSE}
prop_data <- data %>% dplyr::group_by(???, ???) %>% 
                      dplyr::summarise(prop_yanny = mean(???),  
                                       median_RT = median(???),
                                       iqr_RT = IQR(???),
                                       mad_RT = mad(???))

```

Plot... 
```{r warning=FALSE}
ggplot(data = prop_data, 
       mapping = aes(dB_ratio, prop_yanny, color = participant)) +
  geom_point() + # show me the points
  #geom_smooth(aes(group = 1)) + # Challenge! Toggle this! See what it does. Look up geom_smooth for help.
  geom_line(mapping = aes(group = participant)) + # draw a separate line for each participants, linking their responses
  scale_y_continuous(name = "Prop. 'Yanny'", limits = c(0,1)) +
  scale_x_discrete(name = "High/low ratio (dB)", limits = unique(prop_data$dB_ratio)) + 
  theme_classic()
```


### 2. Aggregating Data & Plotting

Let's look at how the levels of the low/high frequency dB ratio affected the mean proportion of "Yanny" (vs. "Laurel") responses, across all participants/blocks/trials...

The `aggregate` function lets you perform a function (in this case, take the mean) of the
values in the variable that comes _before_ the tilda (~). You can group those values by the
variable that comes _after_ the tilda. 


You can use `aggregate`, or the `dplyr::summarise()` method to get summary info from your data. 

```{r}
data_agg <- aggregate(??? ~ ???, data=data, FUN=mean)

data_agg
```

```{r}
group_means <- aggregate(prop_yanny~dB_ratio,data=prop_data, FUN=mean)

ggplot(data = prop_data, mapping = aes(dB_ratio, prop_yanny, color = participant)) +
  ???
  ???
  geom_line(data = group_means, aes(dB_ratio, prop_yanny, group = 1), color = "red", size = 1.5) + 
  scale_y_continuous(name = "Prop. 'Yanny'", limits = c(0,1)) +
  scale_x_discrete(name = "High/low ratio (dB)", limits = unique(prop_data$dB_ratio)) + 
  theme_classic()
```


### 3. Logistic Regression: How did proportion "yanny" responses change with dB ratio?

We are interested in the effects of the dB ratio level on perception of Yanny/Laurel...
Since we're interested in the likelihood of participant choosing one of two categorical variables, we can model this as a binomial ("two-variable") logistic regression. 

You can read more about logistic regression [here](https://uc-r.github.io/logistic_regression#eval), and in many other places online. 

We will first go the simplest route, using only the low/high dB ratio as a predictor:
```{r}
model1 <- glm(??? ~ ???, family = binomial(link='logit'), data = data)

summary(model1)

# Tip: You can save the model output for reference (and so you don't have to run it each time) using he following command. 
# Challenge: look up how to load it in for next time!
# saveRDS(model1, file.path(results_path,"model.rds"))
```
The logistic regression coefficients give the change in the log odds of the outcome for a one unit increase in the predictor variable.

* For every one unit change in the dB ratio, the "log odds" of hearing Yanny (versus Laurel) increases by ____.


### 4. Interpreting the model: Odd Ratio & Confidence Intervals

Usually, the results of a logistic regression are expressed as an "odds ratio." 
To get to this, you need to basically remove the "log" part of the "log odd" interpretation of the coefficients. 
So, you exponentiate the coefficients!

To get the confidence intervals we use the ```confint()``` function...

```{r}
coef(model1)

# odds ratio
exp(coef(model1))

exp( cbind(odd_ratio = coef(model1), confint(model1,level = .95)) )
```
Now we can say that for a one unit increase in the stimulus, the odds of hearing Yanny increase by a factor of about ___. 
Note that the odds ratio for the intercept is not generally interpreted.

Note! Mathematically, probability and odds ratio are two different things. 
Probability is the likelihood that an event will occur. 
Odds ratio is the likelihood that an event will occur in relation to the likelihood that an event will not occur: 

$$prob = p(event)$$
$$odds = p(event)/ p(!event)$$

, where "!" means "not"

That means than an odds ratio > 1 indicates an increased likelihood of the event occuring, 
while an OR < 1 indicates a decreased likelihood. 

Take a look again at the table we generated above. 
How would you describe this in plain language? Write it below!










### 5. Comparing Predicted vs. Observed Values
To make sure our model is not overfitted (only describing our data, not generalizable) or
underfitted (doing a poor job of capturing the variance in our data), we want to plot the 
values the data "predicts" against our data. 

To do this, we use the `predict()` function. It takes the model and the data as inputs, 
and generates predicted values for the outcome variable (what comes before the tilda
in the model). 

Note that if we add the argument `type = "response"` to the function call, 
the `predict()` function returns values on on the same scale as the data. Thus, 
we're getting the odds and not the log-odds. 

```{r}

#You should still have prop_data in your variable space... if not, go back and run it.

pred <- data.frame(p_pred = predict(model1, data, type="response"), # predicted scores
                   dB_ratio = data$dB_ratio) # add the variables we're interested in

ggplot() +
  geom_point(data = prop_data, mapping = aes(dB_ratio, prop_yanny)) +
  geom_line(pred, mapping = aes(dB_ratio, p_pred, group = 1)) + 
  scale_y_continuous(name = "Prop. 'Yanny'", limits = c(0,1)) +
  scale_x_discrete(name = "High/low ratio (dB)") + 
  theme_classic()
```

### 6. Evaluating effect of demographic variables

Aggregate the data so that you saw the effect of age, sex, and years of musical experience. 
How would you do it?
```{r message=FALSE, warning=FALSE}
prop_data_demo <- data %>% dplyr::group_by(sex, dB_ratio) %>% 
                      dplyr::summarise(prop_yanny = mean(resp),
                                       sd = sd(resp),
                                       median_RT = median(RT),
                                       iqr_RT = IQR(RT),
                                       mad_RT = mad(RT))
```

Try plotting the effect of sex, age, or musical experience on proportion yanny responses...
```{r}
ggplot(data = prop_data_demo, mapping = aes(dB_ratio, prop_yanny, color = sex)) +
 geom_point() +
 geom_line(mapping = aes(group = sex)) +
 scale_y_continuous(name = "Prop. 'Yanny'", limits = c(0,1)) +
 scale_x_discrete(name = "High/low ratio (dB)", limits = unique(prop_data$dB_ratio)) + 
 theme_classic()

# ggplot(data = ???, mapping = aes(dB_ratio, prop_yanny, color = ???)) +
#  geom_point() +
#  geom_line(mapping = aes(group = ???)) +
#  scale_y_continuous(name = "Prop. 'Yanny'", limits = c(0,1)) +
#  scale_x_discrete(name = "High/low ratio (dB)") +
#  theme_classic()
```

### 7. Adding other predictors to the mix: Multiple Logistic Regression

Now suppose we also want to model the other variables in our dataset, 
such as age, sex and years of musical experience. 

How would we do that? 

Give it a try, then go ahead and calculate the odd ratio and confidence intervals.

Create a model that incorporates all of these variables as predictors.
- dB ratio
- age
- sex
- years of musical experience

We use the `anova()` function to look at the amount of variance explained by each predictor. 
Note that the order in which predictors are entered matters here!

```{r}
fullmodel <- glm(???, family = binomial(link='logit'), data = data) 
 
summary(fullmodel)

anova(fullmodel, test = "Chisq")
```

#### Predicted vs. Observed Values
Plotting the predicted values from multiple regression can be a bit more complicated 
than plotting the predicted values from single regression. We saw that when plotting the 
predicted results from models 2-4. 

In fact, our data set in quite small, so the risk of overfitting is high. 
However, once you have 3 or more variables predicting an outcome, the regression _line_ that best
describes the data turns into a regression _plane._ (2 variables can be described on a 2D plane, 
but the interplay of 3 or more needs a 3D plane.) 
Plotting multiple regression on an x-y plane may look weird even if it's a decent model for the data. 

So, we're not going to worry about plotting predictions over observed values for these later models. 

Rather, look at the analysis of deviance tables for each models, and at the model comparison table...

#### Model Comparison
To directly compare how well different models capture the variance in the data, we
can again use the ```anova()``` function, but just pass to it each model we defined...

```{r}
anova(???, ???, test="Chisq")
```

The deviance tells us how well our model is doing against a "null" model (a model with only the intercept). 
It's a measure of how well our model fits the data. 

Keep in mind what the chi-square test is measuring:
$$\chi^2 = \sum \frac {(Observed - Expected)^2}{Expected}$$

### Writing it up... 
There's no clear format for reporting the results of a logistic regression in APA format (as far as I know), but most often you will see people report the odds ratios and CIs, as well as indicate which coefficients/variables were significant. 

For the multivariate logistic regression, write up the results for models in which we evaluated the influence of all 
predictors on participant responses. 

Make sure to include the results of the model comparison at the end, and a clear justification (in your own words!) of why we chose Model 1.  

**Important!**: Submit the .Rmd or "knitted" .html version (by clicking the "Knit" button at the top of the script) of your analysis along with your report, 
so that I can check your results against your analysis. 😎

# Resources
Some info Logistic Regression in R can be found  [here](https://www.r-bloggers.com/2015/09/how-to-perform-a-logistic-regression-in-r/).

